{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow from DICED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import h5py\n",
    "import sys\n",
    "from diced import DicedStore\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = DicedStore(\"gs://flyem-public-connectome\")\n",
    "repo = store.open_repo(\"medulla7column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grayscale = repo.get_array(\"grayscale\")\n",
    "groundtruth = repo.get_array(\"groundtruth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_roi():\n",
    "    with open('./json_repo/roi.json', 'r') as f:\n",
    "        roi = json.load(f)\n",
    "    \n",
    "    return roi\n",
    "\n",
    "def get_roi_extent(roi):\n",
    "    roi_extent = []\n",
    "    for loc in roi:\n",
    "        z_extent = slice((loc[0]) * 32, (loc[0] * 32) + 32, None)\n",
    "        y_extent = slice((loc[1]) * 32, (loc[1] * 32) + 32, None)\n",
    "        x_extent = slice((loc[2]) * 32, (loc[3] * 32) + 32, None)\n",
    "        roi_extent.append([z_extent, y_extent, x_extent])\n",
    "        \n",
    "    return roi_extent\n",
    "\n",
    "def get_chunk(array, roi, num_chunks, chunk_depth=32, seed=923):\n",
    "    \"\"\"Get 32 x 32 x 32 arrays from the roi extent\"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    roi_index = random.sample(range(len(roi)), num_chunks)\n",
    "    \n",
    "    for i in roi_index:\n",
    "        z_loc = roi[i][0] * 32\n",
    "        y_loc = roi[i][1] * 32\n",
    "        x_loc = random.choice([loc * 32 for loc in range(roi[i][2], roi[i][3] + 1)])\n",
    "\n",
    "        z_extent = slice(z_loc, (z_loc + 32), None)\n",
    "        y_extent = slice(y_loc, (y_loc + 32), None)\n",
    "        x_extent = slice(x_loc, (x_loc + chunk_depth), None)\n",
    "        \n",
    "        chunk = array[[z_extent, y_extent, x_extent]]\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roi = load_roi()\n",
    "# chunks = get_chunk(grayscale, roi, num_chunks=100, chunk_depth=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset as a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fib_dataset(path, \n",
    "                      roi,\n",
    "                      grayscale,\n",
    "                      groundtruth,\n",
    "                      input_name,\n",
    "                      target_name):\n",
    "    \"\"\"\n",
    "    Argument\n",
    "    :path: The path to save created file. The path should be contain the file name.\n",
    "    :roi: The list from 'roi.json'.\n",
    "    :arr_name: The array what you want to use.\n",
    "    :ds_name: The dataset's name what you want to create.\n",
    "    \"\"\"\n",
    "    \n",
    "    with h5py.File(path, \"a\") as f:\n",
    "        arr_grp = f.create_group(\"array\")\n",
    "        gry_grp = arr_grp.create_group(\"grayscale\")\n",
    "        gt_grp = arr_grp.create_group(\"groundtruth\")\n",
    "                \n",
    "        for i in trange(len(roi)):\n",
    "            r = np.array(roi[i])\n",
    "            rs = r * 32\n",
    "            ze = slice(rs[0], rs[0]+32, None)\n",
    "            ye = slice(rs[1], rs[1]+32, None)\n",
    "            xe = slice(rs[2], rs[3]+32, None)\n",
    "            \n",
    "            gry_arr = grayscale[[ze, ye, xe]].reshape((32, 32, -1))\n",
    "            gry_dset = gry_grp.create_dataset(str(i), data=gry_arr, chunks=(32, 32, 32), compression=\"lzf\")\n",
    "            \n",
    "            gt_arr = groundtruth[[ze, ye, xe]].reshape((32, 32, -1))\n",
    "            gt_dset = gt_grp.create_dataset(str(i), data=gt_arr, chunks=(32, 32, 32), compression=\"lzf\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9186/9186 [4:42:44<00:00,  1.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "create_h5_dataset(\"/media/haein/DATA/FlyEM/fib25.hdf5\", roi, grayscale, groundtruth, \"grayscale\", \"groundtruth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = h5py.File('/media/haein/DATA/FlyEM/fib25.hdf5', 'r')\n",
    "grayscale = h['/array/grayscale/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9186"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = grayscale['0'] # [:, :, 0:32].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9186/9186 [29:14<00:00,  5.24it/s]\n",
      "100%|██████████| 9186/9186 [34:51<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "target = h5py.File('/media/haein/DATA/FlyEM/fib_cube.hdf5', 'a')\n",
    "\n",
    "with h5py.File('/media/haein/DATA/FlyEM/fib25.hdf5', 'r') as original:\n",
    "    arr_path = ['/array/grayscale/', '/array/groundtruth/']\n",
    "    trg_dset_names = ['grayscale', 'groundtruth']\n",
    "\n",
    "    for trg_dset_name in trg_dset_names:\n",
    "        if trg_dset_name == 'grayscale':\n",
    "            trg_dset = target.create_dataset(trg_dset_name, \n",
    "                                             (1, 32, 32, 32), \n",
    "                                             maxshape=(None, 32, 32, 32), \n",
    "                                             compression='lzf', \n",
    "                                             dtype = 'uint8')\n",
    "        else:\n",
    "            trg_dset = target.create_dataset(trg_dset_name, \n",
    "                                             (1, 32, 32, 32), \n",
    "                                             maxshape=(None, 32, 32, 32), \n",
    "                                             compression='lzf', \n",
    "                                             dtype = 'uint64')\n",
    "            \n",
    "\n",
    "\n",
    "    for i in range(2):\n",
    "        org_dset = original[arr_path[i]]\n",
    "        trg_dset = target[trg_dset_names[i]]\n",
    "        \n",
    "        org_dset_list = org_dset.keys()\n",
    "\n",
    "        cube_count = 0\n",
    "\n",
    "        for idx, org_dset_name in enumerate(tqdm(org_dset_list)):\n",
    "            arr = org_dset[org_dset_name][:]\n",
    "            num_cubes = int(arr.shape[2] / 32)\n",
    "\n",
    "            cube_count += num_cubes\n",
    "\n",
    "            trg_dset.resize(cube_count, axis=0)\n",
    "\n",
    "            for i in range(num_cubes):\n",
    "                edge_loc = i * 32\n",
    "                cube = arr[..., edge_loc:edge_loc+32]\n",
    "                trg_dset[(cube_count - num_cubes) + i,...] = cube\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
